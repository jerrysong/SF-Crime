{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First attempt at pulling data from Kaggle and recoding categorical variables of interest into dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Structure\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Others\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "import os.path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data and examine it\n",
    "if os.path.isfile('./train.csv'):\n",
    "    train_data = pd.read_csv('./train.csv')\n",
    "else:\n",
    "    z = zipfile.ZipFile('./train.csv.zip')\n",
    "    train_data = pd.read_csv(z.open('train.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('./test.csv'):\n",
    "    test_data = pd.read_csv('./test.csv')\n",
    "else:\n",
    "    z = zipfile.ZipFile('./test.csv.zip')\n",
    "    test_data = pd.read_csv(z.open('test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before data cleansing, the train data contain 878049 samples, the test data contain 884262 samples.\n",
      "After data cleansing, the train data contain 877982 samples, the test data contain 884186 samples.\n"
     ]
    }
   ],
   "source": [
    "print('Before data cleansing, the train data contain %d samples, the test data contain %d samples.' % \\\n",
    "      (train_data.shape[0], test_data.shape[0]))\n",
    "\n",
    "# Drop samples containing null fields\n",
    "train_data = train_data.dropna()\n",
    "test_data = test_data.dropna()\n",
    "\n",
    "# The boundaries of valid longitude and latitude\n",
    "lon_lat_box = (-122.5247, -122.3366, 37.699, 37.8299)\n",
    "\n",
    "# Drop samples containing invalide longitude and latitude\n",
    "train_data = train_data[train_data.X > lon_lat_box[0]]\n",
    "train_data = train_data[train_data.X < lon_lat_box[1]]\n",
    "train_data = train_data[train_data.Y > lon_lat_box[2]]\n",
    "train_data = train_data[train_data.Y < lon_lat_box[3]]\n",
    "\n",
    "test_data = test_data[test_data.X > lon_lat_box[0]]\n",
    "test_data = test_data[test_data.X < lon_lat_box[1]]\n",
    "test_data = test_data[test_data.Y > lon_lat_box[2]]\n",
    "test_data = test_data[test_data.Y < lon_lat_box[3]]\n",
    "\n",
    "print('After data cleansing, the train data contain %d samples, the test data contain %d samples.' % \\\n",
    "      (train_data.shape[0], test_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LARCENY/THEFT                  174885\n",
      "OTHER OFFENSES                 126165\n",
      "NON-CRIMINAL                    92300\n",
      "ASSAULT                         76872\n",
      "DRUG/NARCOTIC                   53971\n",
      "VEHICLE THEFT                   53772\n",
      "VANDALISM                       44724\n",
      "WARRANTS                        42206\n",
      "BURGLARY                        36754\n",
      "SUSPICIOUS OCC                  31412\n",
      "MISSING PERSON                  25989\n",
      "ROBBERY                         22999\n",
      "FRAUD                           16679\n",
      "FORGERY/COUNTERFEITING          10609\n",
      "SECONDARY CODES                  9985\n",
      "WEAPON LAWS                      8555\n",
      "PROSTITUTION                     7484\n",
      "TRESPASS                         7325\n",
      "STOLEN PROPERTY                  4539\n",
      "SEX OFFENSES FORCIBLE            4387\n",
      "DISORDERLY CONDUCT               4318\n",
      "DRUNKENNESS                      4280\n",
      "RECOVERED VEHICLE                3138\n",
      "KIDNAPPING                       2341\n",
      "DRIVING UNDER THE INFLUENCE      2268\n",
      "RUNAWAY                          1946\n",
      "LIQUOR LAWS                      1903\n",
      "ARSON                            1513\n",
      "LOITERING                        1225\n",
      "EMBEZZLEMENT                     1166\n",
      "SUICIDE                           508\n",
      "FAMILY OFFENSES                   491\n",
      "BAD CHECKS                        406\n",
      "BRIBERY                           289\n",
      "EXTORTION                         256\n",
      "SEX OFFENSES NON FORCIBLE         148\n",
      "GAMBLING                          146\n",
      "PORNOGRAPHY/OBSCENE MAT            22\n",
      "TREA                                6\n",
      "Name: Category, dtype: int64\n",
      "('The percentage of the LARCENY/THEFT is: ', 0.19918973281912386)\n"
     ]
    }
   ],
   "source": [
    "# Show all available crime lables.\n",
    "print(train_data['Category'].value_counts())\n",
    "\n",
    "# Show the percentage of the mode in all data. If the prediction of the model is worse than always predicting the mode,\n",
    "# then we should always predict the mode in the baseline establishment.\n",
    "print('The percentage of the LARCENY/THEFT is: ', train_data['Category'].value_counts()[0] * 1.0 / train_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert the date into a python datetime object.\n",
    "train_data[\"Dates\"] = pd.to_datetime(train_data[\"Dates\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "test_data[\"Dates\"] = pd.to_datetime(test_data[\"Dates\"], format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((877982, 9), (884186, 7))\n",
      "((40000, 5), (10000, 5))\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape, test_data.shape)\n",
    "\n",
    "#let's back stuff up\n",
    "# Before we train the models, we need to divide the data into train data and dev data.\n",
    "train1_data = train_data.copy()\n",
    "\n",
    "# split to train / dev \n",
    "shuffle = np.random.permutation(np.arange(train1_data.shape[0]))\n",
    "train1_data = train1_data.iloc[shuffle]\n",
    "crime_lable_encoder = LabelEncoder()\n",
    "train1_labels = crime_lable_encoder.fit_transform(train1_data['Category'])\n",
    "\n",
    "train1_data[\"Hour\"] = train_data[\"Dates\"].apply(lambda x: x.hour)\n",
    "\n",
    "# drop unnecessary stuff\n",
    "train1_data = train1_data.drop(['Category','Address','Dates','Descript','Resolution'], axis=1)\n",
    "    \n",
    "# normalize X and Y\n",
    "train1_data[['X','Y']] = scale(train1_data[['X','Y']])\n",
    "\n",
    "# let's create integer values for each categories (akin to as.Factor() in R)\n",
    "train1_data['DayOfWeek'] = LabelEncoder().fit_transform(train1_data['DayOfWeek'])\n",
    "train1_data['PdDistrict'] = LabelEncoder().fit_transform(train1_data['PdDistrict'])\n",
    "\n",
    "mini_train_data = train1_data.iloc[:40000]\n",
    "mini_train_labels = train1_labels[:40000]\n",
    "mini_dev_data = train1_data.iloc[40000:50000]\n",
    "mini_dev_labels = train1_labels[40000:50000]\n",
    "\n",
    "print(mini_train_data.shape, mini_dev_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((40000, 5), (10000, 5))\n"
     ]
    }
   ],
   "source": [
    "pca_mod = PCA()\n",
    "pca_mod.fit(train1_data)\n",
    "train_2d = pca_mod.transform(mini_train_data)\n",
    "test_2d = pca_mod.transform(mini_dev_data)\n",
    "\n",
    "print(train_2d.shape, test_2d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The one-versus-rest accuracy for ARSON: 0.802300\n",
      "The one-versus-rest accuracy for ASSAULT: 0.557400\n",
      "The one-versus-rest accuracy for BAD CHECKS: 0.951700\n",
      "The one-versus-rest accuracy for BRIBERY: 0.999500\n",
      "The one-versus-rest accuracy for BURGLARY: 0.535200\n",
      "The one-versus-rest accuracy for DISORDERLY CONDUCT: 0.712300\n",
      "The one-versus-rest accuracy for DRIVING UNDER THE INFLUENCE: 0.729500\n",
      "The one-versus-rest accuracy for DRUG/NARCOTIC: 0.599800\n",
      "The one-versus-rest accuracy for DRUNKENNESS: 0.718200\n",
      "The one-versus-rest accuracy for EMBEZZLEMENT: 0.840100\n",
      "The one-versus-rest accuracy for EXTORTION: 0.998600\n",
      "The one-versus-rest accuracy for FAMILY OFFENSES: 0.998300\n",
      "The one-versus-rest accuracy for FORGERY/COUNTERFEITING: 0.636500\n",
      "The one-versus-rest accuracy for FRAUD: 0.664800\n",
      "The one-versus-rest accuracy for GAMBLING: 0.999900\n",
      "The one-versus-rest accuracy for KIDNAPPING: 0.772100\n",
      "The one-versus-rest accuracy for LARCENY/THEFT: 0.584600\n",
      "The one-versus-rest accuracy for LIQUOR LAWS: 0.753600\n",
      "The one-versus-rest accuracy for LOITERING: 0.846800\n",
      "The one-versus-rest accuracy for MISSING PERSON: 0.518200\n",
      "The one-versus-rest accuracy for NON-CRIMINAL: 0.486900\n",
      "The one-versus-rest accuracy for OTHER OFFENSES: 0.439700\n",
      "The one-versus-rest accuracy for PROSTITUTION: 0.918700\n",
      "The one-versus-rest accuracy for RECOVERED VEHICLE: 0.676700\n",
      "The one-versus-rest accuracy for ROBBERY: 0.647600\n",
      "The one-versus-rest accuracy for RUNAWAY: 0.798300\n",
      "The one-versus-rest accuracy for SECONDARY CODES: 0.608000\n",
      "The one-versus-rest accuracy for SEX OFFENSES FORCIBLE: 0.745000\n",
      "The one-versus-rest accuracy for SEX OFFENSES NON FORCIBLE: 0.999700\n",
      "The one-versus-rest accuracy for STOLEN PROPERTY: 0.598900\n",
      "The one-versus-rest accuracy for SUICIDE: 0.930500\n",
      "The one-versus-rest accuracy for SUSPICIOUS OCC: 0.519900\n",
      "The one-versus-rest accuracy for TRESPASS: 0.540700\n",
      "The one-versus-rest accuracy for VANDALISM: 0.590500\n",
      "The one-versus-rest accuracy for VEHICLE THEFT: 0.551300\n",
      "The one-versus-rest accuracy for WARRANTS: 0.530300\n"
     ]
    }
   ],
   "source": [
    "crimes = np.unique(mini_train_labels)\n",
    "crime_labels = crime_lable_encoder.inverse_transform(crimes)\n",
    "gmm_models = {}\n",
    "\n",
    "for crime, crime_label in zip(crimes, crime_labels):\n",
    "    positive_indices = np.array(np.where(mini_train_labels == crime))[0,:]\n",
    "    if positive_indices.shape[0] < 4:\n",
    "        continue\n",
    "    train_2d_positive = train_2d[positive_indices,] \n",
    "\n",
    "    # negative (no LARCENY nor THEFT) clusters\n",
    "    negative_indices = np.array(np.where(mini_train_labels != crime))[0,:]\n",
    "    train_2d_negative = train_2d[negative_indices,]\n",
    "    \n",
    "    # positive clusters \n",
    "    positive_indices = np.array(np.where(mini_dev_labels == crime))[0,:]\n",
    "    test_2d_data_positive = test_2d[positive_indices,]\n",
    "\n",
    "    # negative  clusters\n",
    "    negative_indices = np.array(np.where(mini_dev_labels != crime))[0,:]\n",
    "    test_2d_data_negative = test_2d[negative_indices,]\n",
    "\n",
    "    \n",
    "    #print(\"for crime {0:d}\".format(crime))\n",
    "    #print(\"positive training sample size is {0:d}\".format(train_2d_positive.shape[0]))\n",
    "      \n",
    "    #print(\"negative training sample size is {0:d}\".format(train_2d_negative.shape[0]))\n",
    "      \n",
    "    #print(\"positive test sample size is {0:d}\".format(test_2d_data_positive.shape[0]))\n",
    "      \n",
    "    #print(\"negative test sample size is {0:d}\".format(test_2d_data_negative.shape[0]))\n",
    "\n",
    "    gmm_positive = GMM(n_components = 4, covariance_type = 'full' )\n",
    "    gmm_positive.fit(train_2d_positive)\n",
    "    gmm_models[crime] = gmm_positive\n",
    "    gmm_negative = GMM(n_components = 4, covariance_type = 'full' )\n",
    "    gmm_negative.fit(train_2d_negative)\n",
    "    log_probas_positive = gmm_positive.score_samples(test_2d)\n",
    "    log_probas_negative = gmm_negative.score_samples(test_2d)\n",
    "\n",
    "\n",
    "    predicted_int_labels = np.greater(log_probas_positive, log_probas_negative).astype(int)\n",
    "    mini_dev_int_labels = np.array(mini_dev_labels == crime, dtype = int)\n",
    "    accuracy = np.sum(np.equal(mini_dev_int_labels, predicted_int_labels)) * 1.0 /mini_dev_int_labels.shape[0]\n",
    "    print(\"The one-versus-rest accuracy for {0:s}: {1:3f}\".format(crime_label, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_labels = [-1] * len(test_2d)\n",
    "\n",
    "for i in xrange(len(test_2d)):\n",
    "    sample = test_2d[i].reshape(1, -1)\n",
    "    max_score = -10e10\n",
    "    for crime, gmm_model in gmm_models.items():\n",
    "        score = gmm_model.score_samples(sample)[0]\n",
    "        if score > max_score:\n",
    "            predicted_labels[i] = crime\n",
    "            max_score = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final accuracy is: 0.071200\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.sum(np.equal(mini_dev_labels, predicted_labels)) * 1.0 / mini_dev_labels.shape[0]\n",
    "print(\"The final accuracy is: {:3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
