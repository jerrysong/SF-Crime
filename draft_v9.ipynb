{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W207 Final Project – San Francisco Crime Classification\n",
    "### By: Daghan, Jerry, and PJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries to facilitate data acquisition & processing, data exploration & visualization, feature engineering, and machine learning experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Structure\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Others\n",
    "from datetime import datetime\n",
    "import re\n",
    "import zipfile\n",
    "import os.path\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_full(statement):\n",
    "    pd.set_option('display.max_rows', len(statement))\n",
    "    print(statement)\n",
    "    pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA ACQUISITION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data from Kaggle: https://www.kaggle.com/c/sf-crime/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load the data and examine it\n",
    "if os.path.isfile('./train.csv'):\n",
    "    train_data = pd.read_csv('./train.csv')\n",
    "else:\n",
    "    z = zipfile.ZipFile('./train.csv.zip')\n",
    "    train_data = pd.read_csv(z.open('train.csv'))\n",
    "\n",
    "print(\"Shape of train_data:\", train_data.shape)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if os.path.isfile('./test.csv'):\n",
    "    test_data = pd.read_csv('./test.csv')\n",
    "else:\n",
    "    z = zipfile.ZipFile('./test.csv.zip')\n",
    "    test_data = pd.read_csv(z.open('test.csv'))\n",
    "\n",
    "print(\"Shape of test_data:\", test_data.shape)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import San Francisco map for visualization\n",
    "map_data = np.loadtxt(\"./sf_map_copyright_openstreetmap_contributors.txt\")\n",
    "len_width_ratio = map_data.shape[0] * 1.0 / map_data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CLEANSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the description of the numerical features to determine outliers. Apparently \"Y=90\" is an outlier. We will drop samples containing outliers. We should also drop samples with NA feature fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Before data cleansing, the train data contain %d samples, the test data contain %d samples.' % \\\n",
    "      (train_data.shape[0], test_data.shape[0]))\n",
    "\n",
    "# Drop samples containing null fields\n",
    "train_data = train_data.dropna()\n",
    "\n",
    "# The boundaries of valid longitude and latitude\n",
    "lon_lat_box = (-122.5247, -122.3366, 37.699, 37.8299)\n",
    "\n",
    "# Drop samples containing invalide longitude and latitude\n",
    "train_data = train_data[train_data.X > lon_lat_box[0]]\n",
    "train_data = train_data[train_data.X < lon_lat_box[1]]\n",
    "train_data = train_data[train_data.Y > lon_lat_box[2]]\n",
    "train_data = train_data[train_data.Y < lon_lat_box[3]]\n",
    "\n",
    "print('After data cleansing, the train data contain %d samples, the test data contain %d samples.' % \\\n",
    "      (train_data.shape[0], test_data.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary goal of this project is to \"predict the category of a crime that occurred, given time and location\", paraphrased from the Kaggle description. Kaggle is \"also encouraging [kagglers] to explore the dataset visually.\" Despite the usefulness of the .head() method in the previous section, further inspection of the data is warranted, especially to better understand the crime category (since that's what we're predicting) as well as time and location (since these are the primary features)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRIME – What are these crime categories?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brief exploration of the crime category section follows, before examining it with respect to time and location. The most important visualizations we chose to keep were 1) a simple chart showing the overall crime distribution without the burden of instrusive labels and 2) a Pareto chart – a duality of bar and line charts that simply and succinctly illustrates both absolute counts and cumulative percentages, while also displaying the labels (since although potentially distracting in a graph, understanding the labels in perspective is essential for later feature engineering and error analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Simple bar chart of all crime occurrences in the training data set\n",
    "categories = dict([(category, group.shape[0]) for category, group in train_data.groupby(train_data[\"Category\"])])\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "plt.bar(np.arange(len(categories)), list(categories.values()))\n",
    "plt.title(\"All crime occurrences in the training data\", fontsize=30)\n",
    "plt.ylabel(\"Crime Occurrences\")\n",
    "plt.xlabel(\"Category (Unlabeled for now)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories = dict([(category, group.shape[0]) for category, group in train_data.groupby(train_data[\"Category\"])])\n",
    "\n",
    "# Dissolve the categories dictionary into a sorted list of values, then labels in descending order\n",
    "categories = sorted(categories.items(), key=lambda x: x[1], reverse=True)\n",
    "categories, counts = ([item[0] for item in categories], [item[1] for item in categories])\n",
    "\n",
    "# Create a Pareto Chart\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ind = np.arange(len(categories))\n",
    "\n",
    "# Bar chart of category and count\n",
    "ax1 = fig.add_subplot(111)\n",
    "ax1.bar(ind, counts)\n",
    "ax1.set_xticks(ind + .5)\n",
    "ax1.set_xticklabels(categories, rotation=90)\n",
    "ax1.set_ylim(ymax=sum(counts))\n",
    "ax1.set_ylabel(\"Crime Occurrences\")\n",
    "\n",
    "# Co-plotted line chart of percentages\n",
    "ax2 = ax1.twinx()\n",
    "percent = 100*np.cumsum(counts)/sum(counts)\n",
    "ax2.plot(ind + .5, percent)\n",
    "ax2.set_ylim(0, 100)\n",
    "ax2.set_ylabel(\"Percentage of Total\")\n",
    "\n",
    "plt.title(\"Absolute counts and cumulative percentages of all crimes\", fontsize=30)\n",
    "plt.show()\n",
    "\n",
    "print(\"The top 9 crimes account for 80% of all instances, the top 5 account for 60%, and the top crime accounts for 20%!\\n\")\n",
    "\n",
    "# Show all available crime lables with exact numbers in a format that does not require head-turning\n",
    "crime_categories = train_data['Category'].value_counts()\n",
    "print('As seen above, these are the %d crime categories:' % (len(crime_categories)))\n",
    "print(crime_categories)\n",
    "crime_category_names = crime_categories.index\n",
    "\n",
    "# Show the percentage of the mode in all data.\n",
    "print('\\nThe percentage of LARCENY/THEFT (the most commonly occurring crime) is: ' + str(round(100*crime_categories[0] * 1.0 / train_data.shape[0], 2)) + '%')\n",
    "print('When predicting, if the model is worse than always predicting the mode, it may be beneficial to always predict the mode (LARCENY/THEFT).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the visualizations above, it is apparent that not all crimes are equal, at least in terms of how common they are. Next, we will examine which areas in San Francisco are more prone to certain types of crime, then finally visualize the time dimension to determine whether crime truly doesn't sleep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOCATION – Where do crimes occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,10))\n",
    "colors = [\"pink\", \"darkturquoise\", \"forestgreen\", \"royalblue\", \"Orange\", \"lightgrey\", \"indianred\", \"sienna\", \"palegoldenrod\", \"mediumorchid\"]\n",
    "train_data[\"Category\"].groupby(train_data[\"PdDistrict\"]).count().sort_values(ascending=False).plot(kind='barh', color=colors)\n",
    "plt.title(\"Total crimes by police district\", fontsize=30)\n",
    "plt.xlabel(\"Crime Occurrences\")\n",
    "plt.ylabel(\"Police District\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Top 5 crimes per district, on the same scale (0 to 45,000 occurrences)\")\n",
    "plt.figure(figsize=(20, 100))\n",
    "colors = [\"royalblue\", \"Orange\", \"indianred\", \"darkturquoise\", \"forestgreen\", \"palegoldenrod\", \"mediumorchid\", \"pink\", \"sienna\", \"lightgrey\"]\n",
    "i = 0\n",
    "for district, group in train_data.groupby(train_data[\"PdDistrict\"]):\n",
    "    p = plt.subplot(20, 3, i+1)\n",
    "    group[\"Category\"].value_counts()[:5].plot(kind='barh', axes=p, fontsize=7, xlim=(0,45000), color=colors[i])\n",
    "    plt.title(district)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Assign a color index to each crime category\n",
    "color_map = dict(zip(crime_category_names, range(len(crime_categories))))\n",
    "\n",
    "# Draw a scatter plot to show the crimes distribution\n",
    "plt.figure(figsize=(20,20))\n",
    "#plt.scatter(train_data.X, train_data.Y, c=train_data.Category.map(color_map), cmap=plt.cm.gist_ncar)\n",
    "plt.scatter(train_data.X, train_data.Y, c=train_data.Category.map(color_map), cmap=plt.cm.gist_ncar, alpha = 0.01)\n",
    "plt.title(\"All crimes visualized with respect to longitude and latitude\", fontsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, the scatter plot with all crimes is not very helpful. Crimes happened everywhere, and we didn't get deeper insight. We will make the scatter plot of every crime separatedly at the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 320))\n",
    "\n",
    "for i in range(len(crime_category_names)):\n",
    "    p = plt.subplot(40, 2, i+1)\n",
    "    crime = crime_category_names[i]\n",
    "    cur_crime_data = train_data[train_data.Category == crime]\n",
    "    plt.title(crime + \" locations\")\n",
    "    p.scatter(cur_crime_data.X, cur_crime_data.Y, alpha = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can spot some trends with the scatterplots above, notably that some crimes are more prevalent at particular locations. For example, despite differing in total occurrences, Drug/Narcotic and Prostitution are both crimes that seem to have a high density on the Northeastern tip of SF. On the other hand, Vehicle Theft and Family Offenses are common in all areas of SF, and are spread out seemingly equally. Observing the density plots may help us to understand the concentration of various crimes, so we'll start with Prostitution and sex-related offenses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Examine one type of crime (prostitution, in this case) more closely and compare with related crimes (other sex offenses)\n",
    "\n",
    "# First, filter relevant data from the training set\n",
    "prostitution_data = train_data[train_data.Category == \"PROSTITUTION\"]\n",
    "sex_offenses = train_data[(train_data.Category == \"SEX OFFENSES FORCIBLE\") | (train_data.Category == \"SEX OFFENSES NON FORCIBLE\")]\n",
    "\n",
    "# Overlay the prostitution location density plot and the sex offenses location density plot over the SF map image\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "xy_lim = list((prostitution_data.X.min(), prostitution_data.X.max(), prostitution_data.Y.min(), prostitution_data.Y.max()))\n",
    "plt.imshow(map_data, extent=xy_lim, cmap=plt.get_cmap('gray'))\n",
    "sns.kdeplot(prostitution_data.X, prostitution_data.Y, n_levels=10, shade=False, cmap=\"bone\")\n",
    "sns.kdeplot(sex_offenses.X, sex_offenses.Y, n_levels=10, shade=False, cmap=\"spring\")\n",
    "plt.title(\"Density plot of PROSTITUTION (white-to-black) vs. SEX OFFENSES (yellow-to-pink)\", fontsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the densities for these sex-related crimes are different, and it may be useful to visualize others as well. However, as we saw with the scatterplots above, there are too many categories (30+) to observe on the same map to get a meaninful visual. Further categorization may be beneficial for co-plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is an attempt to further categorize the crimes into 6 types + an \"other\" category\n",
    "\n",
    "property_related = train_data[(train_data.Category == \"LARCENY/THEFT\") |\n",
    "                              (train_data.Category == \"VEHICLE THEFT\") |\n",
    "                              (train_data.Category == \"VANDALISM\") |\n",
    "                              (train_data.Category == \"BURGLARY\") |\n",
    "                              (train_data.Category == \"TRESPASS\") |\n",
    "                              (train_data.Category == \"STOLEN PROPERTY\") |\n",
    "                              (train_data.Category == \"RECOVERED VEHICLE\") |\n",
    "                              (train_data.Category == \"ARSON\") |\n",
    "                              (train_data.Category == \"ROBBERY\")]\n",
    "\n",
    "person_related = train_data[(train_data.Category == \"ASSAULT\") |\n",
    "                              (train_data.Category == \"MISSING PERSON\") |\n",
    "                              (train_data.Category == \"ROBBERY\") |\n",
    "                              (train_data.Category == \"KIDNAPPING\") |\n",
    "                              (train_data.Category == \"RUNAWAY\") |\n",
    "                              (train_data.Category == \"FAMILY OFFENSES\") |\n",
    "                              (train_data.Category == \"SUICIDE\")]\n",
    "\n",
    "drugs_sex_gambling_related = train_data[(train_data.Category == \"DRUG/NARCOTIC\") |\n",
    "                              (train_data.Category == \"DRUNKENNESS\") |\n",
    "                              (train_data.Category == \"LIQUOR LAWS\") |\n",
    "                              (train_data.Category == \"DRIVING UNDER THE INFLUENCE\") |\n",
    "                              (train_data.Category == \"PROSTITUTION\") |\n",
    "                              (train_data.Category == \"SEX OFFENSES FORCIBLE\") |\n",
    "                              (train_data.Category == \"SEX OFFENSES NON FORCIBLE\") |\n",
    "                              (train_data.Category == \"PORNOGRAPHY/OBSCENE MAT\") |\n",
    "                              (train_data.Category == \"GAMBLING\")]\n",
    "\n",
    "weapon_violence_related = train_data[(train_data.Category == \"WEAPON LAWS\") |\n",
    "                              (train_data.Category == \"ARSON\") |\n",
    "                              (train_data.Category == \"SEX OFFENSES FORCIBLE\")]\n",
    "\n",
    "fraudulent_behavior_related = train_data[(train_data.Category == \"FRAUD\") |\n",
    "                              (train_data.Category == \"FORGERY/COUNTERFEITING\") |\n",
    "                              (train_data.Category == \"BAD CHECKS\") |\n",
    "                              (train_data.Category == \"EMBEZZLEMENT\") |\n",
    "                              (train_data.Category == \"BRIBERY\") |\n",
    "                              (train_data.Category == \"EXTORTION\") |\n",
    "                              (train_data.Category == \"TREA\")]\n",
    "\n",
    "general_misconduct_related = train_data[(train_data.Category == \"LOITERING\") |\n",
    "                              (train_data.Category == \"DISORDERLY CONDUCT\") |\n",
    "                              (train_data.Category == \"SUSPICIOUS OCC\")]\n",
    "\n",
    "other_related = train_data[(train_data.Category == \"OTHER OFFENSES\") |\n",
    "                              (train_data.Category == \"NON-CRIMINAL\") |\n",
    "                              (train_data.Category == \"WARRANTS\") |\n",
    "                              (train_data.Category == \"SECONDARY CODES\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that there are only 7 categories, we could try co-plotting the primary 6 and inspecting the \"other\" crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Examine the 6 broader categories of crime\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "xy_lim = list((train_data.X.min(), train_data.X.max(), train_data.Y.min(), train_data.Y.max()))\n",
    "\n",
    "plt.imshow(map_data, extent=xy_lim, cmap=plt.get_cmap('gray'))\n",
    "for df, name in zip([property_related, person_related, drugs_sex_gambling_related, weapon_violence_related,\n",
    "                     fraudulent_behavior_related, general_misconduct_related], \n",
    "                    [\"Property-related\", \"Person-related\", \"Drugs/Sex/Gambling\", \"Weapon/Violence\",\n",
    "                     \"Fraudulent Behavior\", \"General Misconduct\"]):\n",
    "    shuffle = np.random.permutation(np.arange(df.shape[0]))\n",
    "    samples = df.iloc[shuffle][:len(df)//1000]\n",
    "    sns.kdeplot(samples.X, samples.Y, n_levels=10, shade=False, cmap=\"cool\")\n",
    "plt.title(\"6 Broad categories of crime: property-related, person-related, drugs/sex/gambling, weapon/violence, fraudulent behavior, and general misconduct\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "# Examine \"Other Crimes\" as the 7th category\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "xy_lim = list((other_related.X.min(), other_related.X.max(), other_related.Y.min(), other_related.Y.max()))\n",
    "\n",
    "plt.imshow(map_data, extent=xy_lim, cmap=plt.get_cmap('gray'))\n",
    "shuffle = np.random.permutation(np.arange(other_related.shape[0]))\n",
    "samples = other_related.iloc[shuffle][:len(other_related)//100]\n",
    "sns.kdeplot(samples.X, samples.Y, n_levels=10, shade=False, cmap=\"cool\")\n",
    "plt.title(\"The other crimes\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though fewer categories were used, the co-plot still looks messy. One immediate insight that can be gleaned is that highest crime densities, regardless of the category, are situated in the Northeastern Tip. \"Other,\" nonspecific crimes do not tend to deviate past this hub, perhaps indicating that crime in Western SF may be more likely to be specific (or police are more likely to categorize it as specific, and hence issue an arrest under this more specific category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Visualize density plots for the broad categories against each other\n",
    "\n",
    "# Do property-related and person-related crimes occur in the same places?\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "xy_lim = list((train_data.X.min(), train_data.X.max(), train_data.Y.min(), train_data.Y.max()))\n",
    "\n",
    "plt.imshow(map_data, extent=xy_lim, cmap=plt.get_cmap('gray'))\n",
    "for df, name, col in zip([property_related, person_related], [\"Property-related\", \"Person-related\"], [\"cool\", \"autumn\"]):\n",
    "    shuffle = np.random.permutation(np.arange(df.shape[0]))\n",
    "    samples = df.iloc[shuffle][:len(df)//100]\n",
    "    sns.kdeplot(samples.X, samples.Y, n_levels=20, shade=False, cmap=col)\n",
    "plt.title(\"Property-related (magenta-to-blue) vs. Person-related crimes (yellow-to-red)\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "# How about drugs, sex, and gambling versus weapon/violence?\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "xy_lim = list((train_data.X.min(), train_data.X.max(), train_data.Y.min(), train_data.Y.max()))\n",
    "\n",
    "plt.imshow(map_data, extent=xy_lim, cmap=plt.get_cmap('gray'))\n",
    "for df, name, col in zip([drugs_sex_gambling_related, weapon_violence_related], [\"Drugs/Sex/Gambling\", \"Weapon/Violence\"], [\"cool\", \"autumn\"]):\n",
    "    shuffle = np.random.permutation(np.arange(df.shape[0]))\n",
    "    samples = df.iloc[shuffle][:len(df)//100]\n",
    "    sns.kdeplot(samples.X, samples.Y, n_levels=20, shade=False, cmap=col)\n",
    "plt.title(\"Drugs/Sex/Gambling (magenta-to-blue) vs. Weapon/Violence crimes (yellow-to-red)\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "# What about fradulent behavior and (typically less serious) general misconduct?\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "xy_lim = list((train_data.X.min(), train_data.X.max(), train_data.Y.min(), train_data.Y.max()))\n",
    "\n",
    "plt.imshow(map_data, extent=xy_lim, cmap=plt.get_cmap('gray'))\n",
    "for df, name, col in zip([fraudulent_behavior_related, general_misconduct_related], [\"Fraudulent Behavior\", \"General Misconduct\"], [\"cool\", \"autumn\"]):\n",
    "    shuffle = np.random.permutation(np.arange(df.shape[0]))\n",
    "    samples = df.iloc[shuffle][:len(df)//100]\n",
    "    sns.kdeplot(samples.X, samples.Y, n_levels=10, shade=False, cmap=col)\n",
    "plt.title(\"Fraudulent Behavior (magenta-to-blue) vs. General Misconduct crimes (yellow-to-red)\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After attempting to recategorize crime categories based on the (human-determined) nature of the crime, there still appears to be overlap. Person- and property-related crimes occur in similar locations, as do fraudulent behavior and general misconduct. The largest visual difference is found to be between the following two types of crime: drugs/sex/gambling and weapon/violence, with the former concentrated slightly farther from the Northeastern Tip than most other crimes, and the latter following a similar pattern to property- and person-related crimes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TIME – When do crimes occur?\n",
    "\n",
    "Besides location, time can also offer a rich set of features. Before delving into detailed feature engineering, let's visually explore the primary source of time-related information: the \"Dates\" column. From these timestamps, we can focus our attention on hour, month, and year as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data[\"Dates\"] = pd.to_datetime(train_data[\"Dates\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "train_data[\"Hour\"] = train_data[\"Dates\"].map(lambda x: x.hour)\n",
    "train_data[\"Month\"] = train_data[\"Dates\"].map(lambda x: x.month)\n",
    "train_data[\"Year\"] = train_data[\"Dates\"].map(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, observe the overall trend for all crimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# All crimes by the hour, month, and year\n",
    "plt.figure(figsize=(16, 320))\n",
    "print(\"CAUTION: SCALES ARE DIFFERENT (so only use to notice the trend)\")\n",
    "for i, time in zip(range(3), [\"Year\", \"Month\", \"Hour\"]):\n",
    "    time_data = {}\n",
    "    p = plt.subplot(40, 3, i+1)\n",
    "    for unit in train_data[time].unique():\n",
    "        time_data[unit] = len(train_data[train_data[time] == unit])\n",
    "        \n",
    "    # Plot either a line chart (default) or bar chart (uncomment)\n",
    "    sns.tsplot(data=list(time_data.values()), time=list(time_data.keys()))\n",
    "    #plt.bar(list(time_data.keys()), list(time_data.values()))\n",
    "    \n",
    "    if time == \"Year\":\n",
    "        # 1-by-1 tick marks are too close, resulting in label overlap of the years\n",
    "        plt.xticks(np.arange(train_data[time].unique().min(),train_data[time].unique().max()+1,2))\n",
    "    else:\n",
    "        plt.xticks(np.arange(train_data[time].unique().min(),train_data[time].unique().max()+1,1))\n",
    "    plt.title(\"All crimes by the \" + time.lower())\n",
    "    plt.ylabel(\"Occurrences\")\n",
    "    plt.xlabel(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The incidence of all crimes seemed to have decreased recently, with very low counts for 2015 (leftmost chart). Such a steep decrease (>50% reduction) is odd, and may suggest incomplete data for 2015. If we were to give greater weightage to more recent years, including 2013 and 2014 may be more beneficial than 2015 alone. For all other years, crime occurrences remained at relatively constant levels. Although not shown in this notebook, inspection in Tableau revealed that this is also observable for most days of the month for all districts. There does appear to be large variation by the hour, and to a lesser extent, month (but this is exacerbated by the scale). An interesting trend is that there are fewer instances of all crimes at particular hours (very early hours of the morning) and months (August and December). So, crime might not actually sleep, but it does appear to nap!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# By the hour\n",
    "plt.figure(figsize=(16, 320))\n",
    "print(\"CAUTION: SCALES ARE DIFFERENT (so only use to notice the trend)\")\n",
    "for i in range(len(crime_category_names)):\n",
    "    p = plt.subplot(40, 2, i+1)\n",
    "    crime = crime_category_names[i]\n",
    "    cur_crime_data = train_data[train_data.Category == crime]\n",
    "    hourly_data = {}\n",
    "    for hour in cur_crime_data.Hour.unique():\n",
    "        hourly_data[hour] = len(cur_crime_data[(cur_crime_data.Hour == hour)])\n",
    "    sns.tsplot(data=list(hourly_data.values()), time=list(hourly_data.keys()))\n",
    "    plt.xticks(np.arange(train_data.Hour.unique().min(),train_data.Hour.unique().max()+1,1))\n",
    "    plt.ylabel(\"Occurrences\")\n",
    "    plt.xlabel(\"Hour\")\n",
    "    plt.title(crime + \" (HOURLY)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# By the month\n",
    "plt.figure(figsize=(16, 320))\n",
    "print(\"CAUTION: SCALES ARE DIFFERENT (so only use to notice the trend)\")\n",
    "for i in range(len(crime_category_names)):\n",
    "    p = plt.subplot(40, 2, i+1)\n",
    "    crime = crime_category_names[i]\n",
    "    cur_crime_data = train_data[train_data.Category == crime]\n",
    "    monthly_data = {}\n",
    "    for month in cur_crime_data.Month.unique():\n",
    "        monthly_data[month] = len(cur_crime_data[(cur_crime_data.Month == month)])\n",
    "    sns.tsplot(data=list(monthly_data.values()), time=list(monthly_data.keys()))\n",
    "    plt.xticks(np.arange(train_data.Month.unique().min(),train_data.Month.unique().max()+1,1))\n",
    "    plt.ylabel(\"Occurrences\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.title(crime + \" (MONTHLY)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# By the year\n",
    "plt.figure(figsize=(16, 320))\n",
    "print(\"CAUTION: SCALES ARE DIFFERENT (so only use to notice the trend)\")\n",
    "for i in range(len(crime_category_names)):\n",
    "    p = plt.subplot(40, 2, i+1)\n",
    "    crime = crime_category_names[i]\n",
    "    cur_crime_data = train_data[train_data.Category == crime]\n",
    "    yearly_data = {}\n",
    "    for year in cur_crime_data.Year.unique():\n",
    "        yearly_data[year] = len(cur_crime_data[(cur_crime_data.Year == year)])\n",
    "    sns.tsplot(data=list(yearly_data.values()), time=list(yearly_data.keys()))\n",
    "    plt.xticks(np.arange(train_data.Year.unique().min(),train_data.Year.unique().max()+1,1))\n",
    "    plt.ylabel(\"Occurrences\")\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.title(crime + \" (YEARLY)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partly inspired by the exploratory data analysis and partly by intuition, the features we chose to include and/or engineer are the following:\n",
    "\n",
    "TIME-related: minute, hour, day, month, year, hour zone, season (removed for final model), week of year, day of week & whether the day is a weekday or weekend\n",
    "\n",
    "LOCATION-related: street names, type of street, whether it's an on intersection or a block, the closest police district, valid longitude values, valid latitude values, and a series of transformed longitude and latitude values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform the Date into a python datetime object.\n",
    "train_data[\"Dates\"] = pd.to_datetime(train_data[\"Dates\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "test_data[\"Dates\"] = pd.to_datetime(test_data[\"Dates\"], format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add Minute\n",
    "train_data[\"Minute\"] = train_data[\"Dates\"].map(lambda x: x.minute)\n",
    "test_data[\"Minute\"] = test_data[\"Dates\"].map(lambda x: x.minute)\n",
    "    \n",
    "print(sorted(train_data['Minute'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add Hour\n",
    "train_data[\"Hour\"] = train_data[\"Dates\"].map(lambda x: x.hour)\n",
    "test_data[\"Hour\"] = test_data[\"Dates\"].map(lambda x: x.hour)\n",
    "    \n",
    "print(sorted(train_data['Hour'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add Day\n",
    "train_data[\"Day\"] = train_data[\"Dates\"].map(lambda x: x.day)\n",
    "test_data[\"Day\"] = test_data[\"Dates\"].map(lambda x: x.day)\n",
    "    \n",
    "print(sorted(train_data['Day'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add Month\n",
    "train_data[\"Month\"] = train_data[\"Dates\"].map(lambda x: x.month)\n",
    "test_data[\"Month\"] = test_data[\"Dates\"].map(lambda x: x.month)\n",
    "    \n",
    "print(sorted(train_data['Month'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add Year\n",
    "train_data[\"Year\"] = train_data[\"Dates\"].map(lambda x: x.year - 2003)   \n",
    "test_data[\"Year\"] = test_data[\"Dates\"].map(lambda x: x.year - 2003)\n",
    "\n",
    "print(sorted(train_data['Year'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add Hour Zone\n",
    "def get_hour_zone(hour):\n",
    "    if hour >= 2 and hour < 8: \n",
    "        return 0\n",
    "    elif hour >= 8 and hour < 12: \n",
    "        return 1\n",
    "    elif hour >= 12 and hour < 18: \n",
    "        return 2\n",
    "    elif hour >= 18 and hour < 22: \n",
    "        return 3\n",
    "    elif hour < 2 or hour >= 22: \n",
    "        return 4\n",
    "    \n",
    "train_data[\"Hour_Zone\"] = train_data[\"Hour\"].map(get_hour_zone)\n",
    "test_data[\"Hour_Zone\"] = test_data[\"Hour\"].map(get_hour_zone)\n",
    "\n",
    "print(sorted(train_data['Hour_Zone'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add Season\n",
    "def get_season(month):\n",
    "    if month in set([3, 4, 5]): \n",
    "        return 0\n",
    "    elif month in set([6, 7, 8]): \n",
    "        return 1\n",
    "    elif month in set([9, 10, 11]): \n",
    "        return 2\n",
    "    elif month in set([12, 1, 2]): \n",
    "        return 3\n",
    "    \n",
    "train_data[\"Season\"] = train_data[\"Month\"].map(get_season)\n",
    "test_data[\"Season\"] = test_data[\"Month\"].map(get_season)\n",
    "\n",
    "print(sorted(train_data['Season'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add Week of Year\n",
    "train_data[\"WeekOfYear\"] = train_data[\"Dates\"].map(lambda x: x.weekofyear / 2 - 1)\n",
    "test_data[\"WeekOfYear\"] = test_data[\"Dates\"].map(lambda x: x.weekofyear / 2)\n",
    "\n",
    "print(sorted(train_data['WeekOfYear'].unique()))\n",
    "print(sorted(test_data['WeekOfYear'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add a binary feature standing for whether the day is weekend\n",
    "train_data[\"Is_Weekend\"] = train_data[\"DayOfWeek\"].map(lambda day: 1 if day in set(['Sunday', 'Saturday']) else 0)\n",
    "test_data[\"Is_Weekend\"] = test_data[\"DayOfWeek\"].map(lambda day: 1 if day in set(['Sunday', 'Saturday']) else 0)\n",
    "\n",
    "print(sorted(train_data['Is_Weekend'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add numeric DayOfWeek feature\n",
    "dayofweek_encoder = LabelEncoder()\n",
    "dayofweek_encoder.fit(train_data['DayOfWeek'])\n",
    "\n",
    "train_data[\"DayOfWeek_Num\"] = dayofweek_encoder.transform(train_data['DayOfWeek'])\n",
    "test_data[\"DayOfWeek_Num\"] = dayofweek_encoder.transform(test_data['DayOfWeek'])\n",
    "\n",
    "print(sorted(train_data['DayOfWeek_Num'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add two features, stree1 and steet2, standing for street names. \n",
    "# The address either contains one street, or is the intersection of two streets. If the address contains one street,\n",
    "# the first street should be the original address value, while the second street should be None. Otherwise, the two\n",
    "# street features will contain the two street names respectively.\n",
    "print('Before Transformation:')\n",
    "print_full(train_data['Address'].head(20))\n",
    "\n",
    "# Extract the first street name from the address. If the extracted street name is not in seen_streets, it should be \n",
    "# assigned None anywhere. This applies when a steet name is in test data but not in train data.\n",
    "def extract_street1(address, seen_streets=None):\n",
    "    street1 = address.split(' / ')[0]\n",
    "    if seen_streets is None or street1 in seen_streets:\n",
    "        return street1\n",
    "    else:\n",
    "        return 'None'\n",
    "\n",
    "# Extract the second street name from the address, or None if the address only contains one street name.\n",
    "def extract_street2(address, seen_streets=None):\n",
    "    streets = address.split(' / ')\n",
    "    street2 = 'None' if len(streets) == 1 else streets[1]\n",
    "    if seen_streets is None or street2 in seen_streets:\n",
    "        return street2\n",
    "    else:\n",
    "        return 'None'\n",
    "\n",
    "# This regex pattern will match the block number in an address and we will remove it.\n",
    "re_pattern = '[0-9]+ Block of '\n",
    "addresses = train_data[\"Address\"].map(lambda address: re.sub(re_pattern, '', address))\n",
    "train_data[\"Street1\"] = addresses.apply(extract_street1)\n",
    "train_data[\"Street2\"] = addresses.apply(extract_street2)\n",
    "\n",
    "seen_streets = set(train_data['Street1'].append(train_data['Street2']).unique())\n",
    "seen_streets.discard('None')\n",
    "print('\\nThe number of unique streets in the train data is %d\\n' % (len(seen_streets),))\n",
    "\n",
    "addresses = test_data[\"Address\"].map(lambda address: re.sub(re_pattern, '', address))\n",
    "test_data[\"Street1\"] = addresses.apply(extract_street1, args=(seen_streets,))\n",
    "test_data[\"Street2\"] = addresses.apply(extract_street2, args=(seen_streets,))\n",
    "\n",
    "print('After Transformation:')\n",
    "print_full(train_data['Street1'].head(20))\n",
    "print_full(train_data['Street2'].head(20))\n",
    "\n",
    "# Transform the Address to catogorical data\n",
    "street_encoder = LabelEncoder()\n",
    "seen_streets = list(seen_streets) + ['None']\n",
    "street_encoder.fit(seen_streets)\n",
    "train_data[\"Street1\"] = street_encoder.transform(train_data['Street1'])\n",
    "train_data[\"Street2\"] = street_encoder.transform(train_data['Street2'])\n",
    "test_data[\"Street1\"] = street_encoder.transform(test_data['Street1'])\n",
    "test_data[\"Street2\"] = street_encoder.transform(test_data['Street2'])\n",
    "\n",
    "# Exchange street1 and stree2 values to guarantee the value of street1 is smaller than street2\n",
    "# This step is to avoid the model from thinking \"street1, street2\" != \"street2, street1\"\n",
    "for index, row in train_data.iterrows():\n",
    "    if row['Street1'] > row['Street2']:\n",
    "        row['Street1'], row['Street2'] = row['Street2'], row['Street1']\n",
    "\n",
    "for index, row in test_data.iterrows():\n",
    "    if row['Street1'] > row['Street2']:\n",
    "        row['Street1'], row['Street2'] = row['Street2'], row['Street1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add the address type as a categorical feature.\n",
    "# We will use the street type of the first street, if the address is an intersection of two \n",
    "# streets with different types.\n",
    "\n",
    "# This list can be obtained from inspecting the data\n",
    "valid_street_types = ['AL', 'AV', 'BL', 'BU', 'CR', 'CT', 'DR', 'EX', 'FE', 'HW', 'HY', 'LN', 'MA',\n",
    "                      'PA', 'PL', 'PZ', 'RD', 'RW', 'ST', 'TE', 'TR', 'WA', 'WK', 'WY']\n",
    "street_type_encoder = LabelEncoder()\n",
    "\n",
    "# 'OT' standss for 'Other'. It will be used when an address value is unconventional, or an address type \n",
    "# can only be found in test data but not train data.\n",
    "street_type_encoder.fit(valid_street_types + ['OT'])\n",
    "\n",
    "# This function extracts the street type from a street name\n",
    "def get_street_types(streets):\n",
    "    streets = streets.reshape(streets.shape[0], 1)\n",
    "    # Extract the suffix of the street name\n",
    "    street_types = np.apply_along_axis(lambda street: street[0].split()[-1], 1, streets)\n",
    "    street_types = street_types.reshape(street_types.shape[0], 1)\n",
    "    # Replace the street type by 'OT' if the street type is not a legit value\n",
    "    street_types = np.apply_along_axis(lambda street_type: street_type[0] if street_type[0] in valid_street_types\n",
    "                                       else 'OT', 1, street_types)\n",
    "    \n",
    "    return street_types.reshape(street_types.shape[0], 1)\n",
    "    \n",
    "\n",
    "train_streets = street_encoder.inverse_transform(train_data[\"Street1\"])\n",
    "train_street_types = get_street_types(train_streets)\n",
    "train_data['Street_Type'] = street_type_encoder.transform(train_street_types)\n",
    "\n",
    "test_streets = street_encoder.inverse_transform(test_data[\"Street1\"])\n",
    "test_street_types = get_street_types(test_streets)\n",
    "test_data['Street_Type'] = street_type_encoder.transform(test_street_types)\n",
    "\n",
    "print(sorted(train_data['Street_Type'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add a feature indicating whether the address locates at the intersection of two streets\n",
    "train_data[\"Is_Intersection\"] = train_data[\"Address\"].map(lambda address: 0 if ' / ' in address else 1)\n",
    "test_data[\"Is_Intersection\"] = test_data[\"Address\"].map(lambda address: 0 if ' / ' in address else 1)\n",
    "\n",
    "print(sorted(train_data['Is_Intersection'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add a feature indicating whether the address is with a block number\n",
    "train_data[\"Is_Block\"] = train_data[\"Address\"].map(lambda address: 0 if 'Block' in address else 1)\n",
    "test_data[\"Is_Block\"] = test_data[\"Address\"].map(lambda address: 0 if 'Block' in address else 1)\n",
    "\n",
    "print(sorted(train_data['Is_Block'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add numeric PdDistrict feature\n",
    "discrict_encoder = LabelEncoder()\n",
    "discrict_encoder.fit(train_data['PdDistrict'])\n",
    "\n",
    "train_data[\"PdDistrict_Num\"] = discrict_encoder.transform(train_data['PdDistrict'])\n",
    "test_data[\"PdDistrict_Num\"] = discrict_encoder.transform(test_data['PdDistrict'])\n",
    "\n",
    "print(sorted(train_data['PdDistrict_Num'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Normalize X and Y\n",
    "print('There are %d unique longitude values, %d unique latitude values' % (train_data['X'].nunique(), \n",
    "                                                                           train_data['Y'].nunique()))\n",
    "\n",
    "xy_scalar = preprocessing.StandardScaler().fit(train_data[['X', 'Y']])\n",
    "train_data[['X', 'Y']] = xy_scalar.transform(train_data[['X', 'Y']])\n",
    "test_data[['X', 'Y']] = xy_scalar.transform(test_data[['X', 'Y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X-Y plane rotation and space transformation to extract more spatial information\n",
    "# 2-dimensional rotation based on below functions:\n",
    "# rotated x = xcos - ysin\n",
    "# rotated y = xsin + ycos\n",
    "# cartesian space -> polar space\n",
    "\n",
    "cos_30 = 1.732/2\n",
    "sin_30 = 1./2\n",
    "cos_45 = .707\n",
    "sin_45 = .707\n",
    "cos_60 = 1./2\n",
    "sin_60 = 1.732/2\n",
    "\n",
    "train_data[\"Rot30_X\"] = train_data['X'] * cos_30 - train_data['Y'] * sin_30 \n",
    "train_data[\"Rot30_Y\"] = train_data['X'] * sin_30 + train_data['Y'] * cos_30\n",
    "train_data[\"Rot45_X\"] = train_data['X'] * cos_45 - train_data['Y'] * sin_45  \n",
    "train_data[\"Rot45_Y\"] = train_data['X'] * sin_45 + train_data['Y'] * cos_45\n",
    "train_data[\"Rot60_X\"] = train_data['X'] * cos_60 - train_data['Y'] * sin_60  \n",
    "train_data[\"Rot60_Y\"] = train_data['X'] * sin_60 + train_data['Y'] * cos_60\n",
    "train_data[\"Radius\"] = np.sqrt(train_data['X'] ** 2 + train_data['Y'] ** 2)\n",
    "train_data[\"Angle\"] = np.arctan2(train_data['X'], train_data['Y'])\n",
    "\n",
    "test_data[\"Rot30_X\"] = test_data['X'] * cos_30 - test_data['Y'] * sin_30  \n",
    "test_data[\"Rot30_Y\"] = test_data['X'] * sin_30 + test_data['Y'] * cos_30\n",
    "test_data[\"Rot45_X\"] = test_data['X'] * cos_45 - test_data['Y'] * sin_45  \n",
    "test_data[\"Rot45_Y\"] = test_data['X'] * sin_45 + test_data['Y'] * cos_45\n",
    "test_data[\"Rot60_X\"] = test_data['X'] * cos_60 - test_data['Y'] * sin_60  \n",
    "test_data[\"Rot60_Y\"] = test_data['X'] * sin_60 + test_data['Y'] * cos_60\n",
    "test_data[\"Radius\"] = np.sqrt(test_data['X'] ** 2 + test_data['Y'] ** 2)\n",
    "test_data[\"Angle\"] = np.arctan2(test_data['X'], test_data['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# View the description of the numerical features again to ensure everything is right\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform Category to categorical data\n",
    "criminal_labels = sorted(train_data['Category'].unique())\n",
    "labels_map = dict(zip(criminal_labels, range(len(criminal_labels))))\n",
    "train_data['Category_Num'] = train_data['Category'].map(labels_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all of the above features will be used for the final model, because some may have low importances and possibly act as noise to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELS COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(train_data.info())\n",
    "\n",
    "# Define the columns of all available features here\n",
    "time_features = ['Minute', 'Hour', 'Day', 'Month', 'Year', 'Hour_Zone', 'Season', \n",
    "                 'WeekOfYear', 'DayOfWeek_Num', 'Is_Weekend']\n",
    "\n",
    "address_features = ['Street1', 'Street2', 'Street_Type', 'PdDistrict_Num', 'Is_Intersection', 'Is_Block']\n",
    "\n",
    "geometry_features = ['X', 'Y', 'Rot45_X', 'Rot45_Y', 'Rot30_X', 'Rot30_Y', \n",
    "                     'Rot60_X', 'Rot60_Y', 'Radius', 'Angle']\n",
    "\n",
    "all_features = time_features + address_features + geometry_features\n",
    "\n",
    "print('The total features count is %d' % len(all_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# perform PCA\n",
    "pca_mod = PCA()\n",
    "pca_mod.fit(train_data[all_features])\n",
    "\n",
    "evr = pca_mod.explained_variance_ratio_\n",
    "s_evr = np.cumsum(np.concatenate(([0], evr)))\n",
    "\n",
    "print('Cumulative explained variance: \\n', s_evr)\n",
    "\n",
    "plt.plot(range(len(s_evr)),s_evr)\n",
    "plt.xlabel('number components')\n",
    "plt.ylabel('sum of explained variance ratios')\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out the applying PCA to our model will decrease the performance, probably because essential information is lost in the PCA process. Besides, we don't have millions of features which render the PCA process a must. So we will not apply PCA here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below may fail to produce all log loss values because the shape of the predicted probabilities matrix doesn't match the shape of the [n_samples * n_categories] matrix in the log_loss function. This is essentially a defect in the sklearn implementation of predict_proba function, which is beyond our ability to fix. When the predict_proba function produces an all-zero column in the output matrix, it will omit it automatically. There is no way to prevent it from doing it, which results into the unmatched matrix shape. To avoid failure for the entire cell, we are using try, exception blocks. However, if there is a failure, please re-run the cell again to try to obtain all log loss values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(train_data):\n",
    "    encoded_train_data = train_data\n",
    "\n",
    "    encoded_train_data = pd.concat([encoded_train_data, \n",
    "                                    pd.get_dummies(pd.Series(encoded_train_data['PdDistrict_Num']), prefix='PdDistrict')], axis=1)\n",
    "    encoded_train_data = pd.concat([encoded_train_data, \n",
    "                                    pd.get_dummies(pd.Series(encoded_train_data['DayOfWeek_Num']), prefix='DayOfWeek')], axis=1)\n",
    "    encoded_train_data = pd.concat([encoded_train_data, \n",
    "                                    pd.get_dummies(pd.Series(encoded_train_data['Street_Type']), prefix='Street_Type')], axis=1)\n",
    "    encoded_train_data = pd.concat([encoded_train_data, \n",
    "                                    pd.get_dummies(pd.Series(encoded_train_data['Season']), prefix='Season')], axis=1)\n",
    "    encoded_train_data = pd.concat([encoded_train_data, \n",
    "                                    pd.get_dummies(pd.Series(encoded_train_data['Hour_Zone']), prefix='Hour_Zone')], axis=1)\n",
    "    encoded_train_data = encoded_train_data.drop(['Street_Type', 'Season', 'Hour_Zone', 'DayOfWeek_Num', 'PdDistrict_Num', \n",
    "                                                  'Street1', 'Street2'], axis=1)\n",
    "\n",
    "    return encoded_train_data\n",
    "\n",
    "sample_number = 100000\n",
    "mini_train_data, mini_dev_data, mini_train_labels, mini_dev_labels = train_test_split(train_data[:sample_number][all_features], \n",
    "                                                                                      train_data[:sample_number]['Category_Num'], \n",
    "                                                                                      test_size=0.5)\n",
    "\n",
    "# K Neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(mini_train_data, mini_train_labels)\n",
    "pred_probs = knn.predict_proba(mini_dev_data)\n",
    "try:\n",
    "    knn_loss = log_loss(mini_dev_labels, pred_probs)\n",
    "except:\n",
    "    knn_loss = np.nan\n",
    "\n",
    "\n",
    "# Naive Bayes\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(mini_train_data, mini_train_labels)\n",
    "pred_probs = gaussian.predict_proba(mini_dev_data)\n",
    "try:\n",
    "    nb_loss = log_loss(mini_dev_labels, pred_probs)\n",
    "except:\n",
    "    nb_loss = np.nan\n",
    "\n",
    "# Logistic Regression\n",
    "logreg = LogisticRegression(C=0.01, solver='newton-cg', tol=0.0001, multi_class='multinomial')\n",
    "logreg.fit(one_hot_encode(mini_train_data), mini_train_labels)\n",
    "pred_probs = logreg.predict_proba(one_hot_encode(mini_dev_data))\n",
    "try:\n",
    "    logreg_loss = log_loss(mini_dev_labels, pred_probs)\n",
    "except:\n",
    "    logreg_loss = np.nan\n",
    "\n",
    "# Decision Tree\n",
    "decision_tree = DecisionTreeClassifier(max_features='log2', max_depth=200, min_samples_split=50)\n",
    "decision_tree.fit(mini_train_data, mini_train_labels)\n",
    "pred_probs = decision_tree.predict_proba(mini_dev_data)\n",
    "try:\n",
    "    dt_loss = log_loss(mini_dev_labels, pred_probs)\n",
    "except:\n",
    "    dt_loss = np.nan\n",
    "\n",
    "# Random Forest\n",
    "random_forest = RandomForestClassifier(max_features='log2', max_depth=200, n_estimators=128, min_samples_split=50, n_jobs=-1)\n",
    "random_forest.fit(mini_train_data, mini_train_labels)\n",
    "pred_probs = random_forest.predict_proba(mini_dev_data)\n",
    "pred_labels = random_forest.predict(mini_dev_data)\n",
    "try:\n",
    "    rf_loss = log_loss(mini_dev_labels, pred_probs)\n",
    "except:\n",
    "    rf_loss = np.nan\n",
    "\n",
    "# Display the rank of the models\n",
    "models = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'Decision Tree', 'K Neighbors'],\n",
    "    'Log_Loss': [logreg_loss, rf_loss, nb_loss, dt_loss, knn_loss]})\n",
    "print(models.sort_values(by='Log_Loss', ascending=True).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline model comparison shows that the Random Forest and Logistic Regression outperform other models greatly. Between these two models, we think Random Forest may be the better option theoretically and practically. Our data set contains a mix of continous numerical features and categorical features. The scope, mean, and variance of those feature variables are very different. The Random Forest model will split at the best point of a feature variable, so whether it is continuous or categorical doesn't matter that much for Random Forest. In contrast, the best practice for Logistic Regression is to one-hot encode all categorical features before training the model. Since we have a huge number of categorical features, one-hot encoding will increase the scale of our train data set to the next level and we will end up having a pretty sparse train data matrix, which is not ideal for Regression models. Even if we do that, its score in the baseline comparison is not as good as the Random Forest. We didn't include the score of SVM and Nerual Network here but we have done that separately (and may it include in the Appendix). Training SVM and Neural Network with huge data set will consume incredibly amount of time and computer memory, i.e., over 10 hours to train a single model with a 8 GM memory computer. Even when sampling tens of thousands of samples, SVM performance was not as good as performance with Random Forest. SVM may be superior compared to other models when the feaure number is greater than the sample number, while neural network is very sensitive to the tunning of hypeparameters. Due to these issues, we believe that these two are not the best models for this project. From now on, we will stick to the Random Forest in the later sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Divide data into train and dev data set and conduct cross-validation\n",
    "# Use all samples here to get a comprehensive insight of its performance and use the result here for error analysis \n",
    "mini_train_data, mini_dev_data, mini_train_labels, mini_dev_labels = train_test_split(train_data[all_features], \n",
    "                                                                                      train_data['Category_Num'], \n",
    "                                                                                      test_size=0.5)\n",
    "\n",
    "random_forest = RandomForestClassifier(max_features=None, max_depth=50, n_estimators=50, min_samples_split=200, \n",
    "                                       n_jobs=-1)\n",
    "random_forest.fit(mini_train_data, mini_train_labels)\n",
    "\n",
    "pred_probs = random_forest.predict_proba(mini_dev_data)\n",
    "pred_labels = random_forest.predict(mini_dev_data)\n",
    "\n",
    "if mini_dev_labels.nunique() != pred_probs.shape[1]:\n",
    "    print('Please run the cell again to get the multiclass loss.')\n",
    "else:\n",
    "    total_loss = log_loss(mini_dev_labels, pred_probs)\n",
    "    print('The multiclass loss of Random Forest model is %.4f' % total_loss)\n",
    "    \n",
    "    rf_accuracy = np.mean(mini_dev_labels == pred_labels)\n",
    "    print('The accuracy of Random Forest model is %.4f' % rf_accuracy)\n",
    "    \n",
    "    feature_weights = pd.DataFrame({'Feature': all_features, 'Weight': random_forest.feature_importances_})\n",
    "    feature_weights = feature_weights.sort_values(by='Weight', ascending=False).reset_index(drop=True)\n",
    "    print(feature_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very suprising that Minute is the most important feature, while the Month just doesn't matter for Random Forest. This tells us that never ignoring a feature or put extra weights on a feature based on intuition. Only data itself can judge whether a feature is important or not. However, it is also possible that the model gets confused here, and overfit for the noise in the Minute feature. If that is true, this model will do a poor job in prediction. Here we believe that these features are weighted correctly, because we have a large number of trees in the forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Exclude unimportant features from the features set for the final model\n",
    "weight_threshold = 0\n",
    "data_features = feature_weights['Feature'][feature_weights['Weight'] > 0.02]\n",
    "print('The select features are as following:')\n",
    "print(data_features)\n",
    "\n",
    "data_features = data_features.values\n",
    "print('The count of selected features is %d' % len(data_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERROR ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Histogram of predictions\n",
    "\n",
    "# Upper y-limit is the max of the two occurences + some fraction of the max\n",
    "y_max = max(max(pd.Series(pred_labels).value_counts()), max(pd.Series(mini_dev_labels).value_counts()))\n",
    "y_upper = y_max + 0.025 * y_max\n",
    "# Originally: ax.set_ylim(0,170000)\n",
    "\n",
    "fig = plt.figure(figsize = (16,8))\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "ax.set_ylim(0, y_upper)\n",
    "plt.hist(mini_dev_labels, bins=np.arange(39)-0.5, label='actual labels')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.set_ylim(0, y_upper)\n",
    "plt.hist(pred_labels, bins=np.arange(39)-0.5, label='predicted labels')\n",
    "l = plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis of the actual vs. predicted labels show that our model is overpredicting 5 labels and completely ignores many others. To remedy that, we are going to try to _\"balance\"_ the classifier weights based on the prior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "random_forest1 = RandomForestClassifier(class_weight='balanced', max_features=None, min_samples_split=200, \n",
    "                                       n_estimators=100)\n",
    "random_forest1.fit(mini_train_data, mini_train_labels)\n",
    "pred_probs1 = random_forest1.predict_proba(mini_dev_data)\n",
    "pred_labels1 = random_forest1.predict(mini_dev_data)\n",
    "\n",
    "rf_accuracy1 = np.mean(mini_dev_labels == pred_labels1)\n",
    "print('The accuracy of Random Forest model is {0:4f}'.format(rf_accuracy1))\n",
    "\n",
    "if mini_dev_labels.nunique() != pred_probs1.shape[1]:\n",
    "    print('Please run the cell again to get the multiclass loss.')\n",
    "else:\n",
    "    total_loss1 = log_loss(mini_dev_labels, pred_probs1)\n",
    "    print('The multiclass loss of Random Forest model is {0:4f}'.format(total_loss1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Histogram of predictions\n",
    "\n",
    "# Upper y-limit is the max of the two occurences + some fraction of the max\n",
    "y_max = max(max(pd.Series(pred_labels1).value_counts()), max(pd.Series(mini_dev_labels).value_counts()))\n",
    "y_upper = y_max + 0.025 * y_max\n",
    "\n",
    "fig = plt.figure(figsize = (16,8))\n",
    "\n",
    "ax = fig.add_subplot(121)\n",
    "ax.set_ylim(0,y_upper)\n",
    "plt.hist(mini_dev_labels, bins=np.arange(39)-0.5, label='actual labels')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "ax = fig.add_subplot(122)\n",
    "ax.set_ylim(0,y_upper)\n",
    "plt.hist(pred_labels1, bins=np.arange(39)-0.5, label='predicted labels')\n",
    "l = plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this model reduces overprediction of few labels (and has more predicted labels), the overall log_loss accuracy is worse. So we are going to continue to use the default option for the class weigths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# let's create a vector of log_loss for each row\n",
    "pred_probs1 = pred_probs.copy()\n",
    "labels = [x for x in range(39)]\n",
    "llv = np.zeros(pred_probs1.shape[0])\n",
    "\n",
    "for row in range(pred_probs1.shape[0]):\n",
    "    llv[row] = log_loss([mini_dev_labels.iloc[row]],pred_probs1[row, :].reshape(1,39), labels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(np.mean(llv))\n",
    "mean_loss = log_loss(mini_dev_labels, pred_probs)\n",
    "fig = plt.figure(figsize = (16,8))\n",
    "ax = fig.add_subplot(111)\n",
    "result = plt.hist(llv, bins = 100)\n",
    "plt.title('Histrogram of log_loss values for each prediction')\n",
    "plt.axvline(mean_loss, color='c', linestyle='dashed', linewidth=2)\n",
    "props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "title_string = \"mean log_loss is {0:3f}\".format(mean_loss)\n",
    "txt = ax.text(0.0, 0.95, title_string, transform=ax.transAxes, fontsize=14,\n",
    "        verticalalignment='top', bbox=props)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there are a few outliers in the neighborhood of 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline log_loss\n",
    "For each row, a uniform probability prediction (no machine learning required), where each label has a 1/39 probability would give a log_loss score of:  \n",
    "$$\n",
    "\\begin{aligned}\n",
    "log\\_loss &= -\\log(\\frac{1}{39})  \\\\\n",
    "          &= 3.663562\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# baseline log_loss for uniform distribution (where all probas are 1)\n",
    "print(\"The log_loss from uniform probability (i.e, no choice) is: {0:5f}\".format(-math.log(1/39)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One quick fix is to find all the labels whose mean log_loss score is above the baseline log_loss score and replace those labels with an \"I don't know\" probability where each label is equal probability of $\\frac{1}{39}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for each category, recompute the log_loss score\n",
    "sum_llv = 0\n",
    "sum_size = 0\n",
    "mean_llv_per_label = np.empty((39,))\n",
    "for c in range(39):\n",
    "    size = llv[pred_labels == c].shape[0]\n",
    "    if size:\n",
    "        mean_llv_per_label[c] = np.mean(llv[pred_labels == c])\n",
    "        print(\"for label: {0:2d}, there are {1:3} predictions with the mean log_loss of: {2:5f}\"\n",
    "          .format(c,size,mean_llv_per_label[c]))\n",
    "        sum_llv += mean_llv_per_label[c]*size\n",
    "        sum_size += size\n",
    "print(sum_llv/sum_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, none of the labels have a mean log_loss score higher than 3.6, so this fix is not helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the worse performing predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the top 10 worse performing partitions are\n",
    "ind = np.argpartition(llv, -10)[-10:]\n",
    "print(\"Worst predictions are:\")\n",
    "print(llv[ind])\n",
    "\n",
    "print(\"for these indexes\")\n",
    "print(ind)\n",
    "\n",
    "\n",
    "#print(pred_labels[ind])\n",
    "#pred_probs[ind]\n",
    "\n",
    "print(\"these are the predicted labels\")\n",
    "print(pred_labels[ind])\n",
    "\n",
    "print(\"these are the actual labels\")\n",
    "print(mini_dev_labels.iloc[ind])\n",
    "\n",
    "tmp = mini_dev_data.copy().iloc[500000:]\n",
    "print(\"there are the inccorect dev points\")\n",
    "for i in ind:\n",
    "    print(mini_dev_data.iloc[i])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, there doesn't seem to be an obvious issue with these samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing the predictions \n",
    "We are going to add a small value to all the predictions so that we don't have any 0 value probability.   \n",
    "Note that while the $\\sum{row_{predictions}} > {1}$ for each row of the prediction matrix, this is not an issue. Log_loss function used by Python and Kaggle rescales the matrix back to $\\sum{row_{predictions}} = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Smoothing the predictions - We are going to add a small value to each probability and compute the log_loss score\n",
    "pred_probs2 = pred_probs.copy()\n",
    "x = []\n",
    "y = []\n",
    "for s in range(1, 100):\n",
    "    smoothing = s*(10**-5) \n",
    "    x.append(smoothing)\n",
    "    #print(smoothing)\n",
    "    t3 = np.add(pred_probs2 , (np.ones(pred_probs2.shape)*smoothing))\n",
    "    ll = log_loss(mini_dev_labels, t3)\n",
    "    y.append(ll)\n",
    "    #print(smoothing,ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plotting the log_loss scores to find out the min value\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim(min(x),max(x))\n",
    "ax.set_ylim(min(y),max(y))\n",
    "plt.scatter(x,y)\n",
    "plt.title('Log_loss scatter vs smoothing parameter plot')\n",
    "min_value = np.argmin(y)\n",
    "\n",
    "print(\"We get the lowest log_loss score of: {0:f}, with smooting parameter: {1:f}\".\n",
    "      format(y[min_value],x[min_value]))\n",
    "print(\"The improvement is {0:3f}%\".format(1-(y[min_value]/2.34945027229)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: End of Testing for Jerry3 section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed that excluding unimportant parameters can improve the accuracy slightly. This is probably because the model is prone to noise and the predicted results have greater variance when unimportant features are there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Warning: doing cross validation on large data set will be extremly time and memory consuming. It takes a computer\n",
    "# with 16GB memory about 45-60 mins to run the cross validation model below. Carefully select the tunning parameters\n",
    "# set before running.\n",
    "\n",
    "n_estimators = [32, 64, 128, 160]\n",
    "max_features = ['sqrt', 'log2', None]\n",
    "max_depth = [10, 50, 100, 125, 150, None]\n",
    "min_samples_split = [10, 50, 100, 200, 500]\n",
    "# Note: Daghan is testing with class_weight as well\n",
    "\n",
    "cv_clf = GridSearchCV(RandomForestClassifier(n_jobs=2), {'n_estimators': n_estimators, \n",
    "                                                 'max_features': max_features,\n",
    "                                                 'max_depth': max_depth,\n",
    "                                                 'min_samples_split': min_samples_split})\n",
    "\n",
    "# The \"optimal\" parameters computed here may actually increase the submission score sometime, \n",
    "# probably due to overfitting.\n",
    "cv_clf.fit(train_data[:50000][data_features], train_data[:50000]['Category_Num'])\n",
    "print(cv_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We understand that the GridSeachCV use 'label prediction accuracy score' as the metric by default, which is not necessarily consistent with the log-loss. However, we cannot use log-loss in it, though it accepts us to pass a score metric parameter. If we use log-loss in GridSeachCV, we will encounter exactly the same failure as dicussed in the Model Comparison section, the matrix shape unmatch. Since this is a defect in sklearn library which we cannot fix, we will use the default scroe metric here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMISSION RESULTS GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will use the Random Forest to establish the baseline.\n",
    "# Retrain the Random Forest model with full train data\n",
    "random_forest = RandomForestClassifier(max_features=None, max_depth=50, n_estimators=50, min_samples_split=200,\n",
    "                                       n_jobs=-1)\n",
    "random_forest.fit(train_data[data_features], train_data['Category_Num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "transformed_test_data = test_data[data_features]\n",
    "transformed_test_data.info()\n",
    "\n",
    "# Print which feature column contains NA value\n",
    "print(transformed_test_data.isnull().any())\n",
    "\n",
    "# Fill the NA feature fields in the test data with the mean of that feature\n",
    "transformed_test_data = transformed_test_data.fillna(transformed_test_data.mean())\n",
    "\n",
    "predictions = random_forest.predict_proba(transformed_test_data)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Smooth the predictions\n",
    "predictions = np.add(predictions , (np.ones(predictions.shape) * smoothing_parameter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate the submission dataframe\n",
    "submission = np.column_stack((range(predictions.shape[0]), predictions))\n",
    "submission = pd.DataFrame(data=submission, columns=['Id'] + criminal_labels)\n",
    "submission['Id'] = submission['Id'].astype(int)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the submission csv file\n",
    "submission.to_csv('submission.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SVM and Neural Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Due to the computationally expensive nature of SVMs and Neural Nets, we will have to sample from the trianing set.\n",
    "sample_limit = 10000\n",
    "\n",
    "mini_train_data2 = mini_train_data[:sample_limit].copy()\n",
    "mini_dev_data2 = mini_dev_data[:sample_limit].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# When using SVMs, try rescaling data so one feature doesn't overpower another\n",
    "\n",
    "# Rescale continuous variables to [0,1]:\n",
    "# Long                   877982 non-null float64\n",
    "# Lat                    877982 non-null float64\n",
    "# Rot45_X                877982 non-null float64\n",
    "# Rot45_Y                877982 non-null float64\n",
    "# Rot30_X                877982 non-null float64\n",
    "# Rot30_Y                877982 non-null float64\n",
    "# Rot60_X                877982 non-null float64\n",
    "# Rot60_Y                877982 non-null float64\n",
    "# Radius                 877982 non-null float64\n",
    "# Theta                  877982 non-null float64\n",
    "\n",
    "for feature in [\"Long\", \"Lat\", \"Rot45_X\", \"Rot45_Y\", \"Rot30_X\", \"Rot30_Y\", \"Rot60_X\", \"Rot60_Y\", \"Radius\", \"Theta\"]:\n",
    "    scaler = preprocessing.MinMaxScaler().fit(mini_train_data2[feature].reshape(-1,1))\n",
    "    mini_train_data2[feature] = scaler.transform(mini_train_data2[feature].reshape(-1,1))\n",
    "    mini_dev_data2[feature] = scaler.transform(mini_dev_data2[feature].reshape(-1,1))\n",
    "    \n",
    "mini_train_data2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Categorical variables should also have [0,1] range (i.e. binarized):\n",
    "\n",
    "# Minute                 877982 non-null int64\n",
    "# Hour                   877982 non-null int64\n",
    "# Month                  877982 non-null int64\n",
    "# Year                   877982 non-null int64\n",
    "# DayOfWeek_Category     877982 non-null int64\n",
    "# Hour_Zone              877982 non-null int64\n",
    "# Is_Weekday             877982 non-null int64\n",
    "# Street1                877982 non-null int64\n",
    "# Is_Intersection        877982 non-null int64\n",
    "# Is_Block               877982 non-null int64\n",
    "# PdDistrict_Category    877982 non-null int64\n",
    "# Street_Type            877982 non-null int64\n",
    "\n",
    "for feature in [\"Minute\", \"Hour\", \"Month\", \"Year\", \"DayOfWeek_Category\", \"Hour_Zone\", \"Is_Weekday\", \"Street1\", \"Is_Intersection\", \"Is_Block\", \"PdDistrict_Category\", \"Street_Type\"]:\n",
    "    for unique_feature in mini_train_data2[feature].unique():\n",
    "        name = str(feature) + \"_\" + str(unique_feature)\n",
    "        mini_train_data2[name] = pd.Series(mini_train_data2[feature] == unique_feature, dtype=int)\n",
    "        mini_dev_data2[name] = pd.Series(mini_dev_data2[feature] == unique_feature, dtype=int)\n",
    "#         print(name)\n",
    "#         break\n",
    "mini_train_data2.drop([\"Minute\", \"Hour\", \"Month\", \"Year\", \"DayOfWeek_Category\", \"Hour_Zone\", \"Is_Weekday\", \"Street1\", \"Is_Intersection\", \"Is_Block\", \"PdDistrict_Category\", \"Street_Type\"], axis=1, inplace=True)\n",
    "mini_dev_data2.drop([\"Minute\", \"Hour\", \"Month\", \"Year\", \"DayOfWeek_Category\", \"Hour_Zone\", \"Is_Weekday\", \"Street1\", \"Is_Intersection\", \"Is_Block\", \"PdDistrict_Category\", \"Street_Type\"], axis=1, inplace=True)\n",
    "mini_train_data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_clf = SVC(kernel='poly', decision_function_shape='ovr', probability=True, cache_size=1000)\n",
    "svm_clf.fit(mini_train_data2, mini_train_labels[:sample_limit])\n",
    "pred_labels = svm_clf.predict(mini_dev_data2)\n",
    "svm_accuracy = np.mean(mini_dev_labels[:sample_limit] == pred_labels)\n",
    "print(\"SVM accuracy:\", svm_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = svm_clf.predict_proba(mini_dev_data2)\n",
    "try: \n",
    "    total_loss = log_loss(mini_dev_labels[:sample_limit], preds, labels = mini_dev_labels[:sample_limit].unique())\n",
    "except:\n",
    "    total_loss = np.nan\n",
    "print('The multiclass loss of SVM model is %.4f' % total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ann = MLPClassifier()\n",
    "ann.fit(mini_train_data2, mini_train_labels[:sample_limit])\n",
    "pred_labels = ann.predict(mini_dev_data2)\n",
    "ann_accuracy = np.mean(mini_dev_labels[:sample_limit] == pred_labels)\n",
    "print(\"ANN accuracy:\", ann_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = ann.predict_proba(mini_dev_data2)\n",
    "total_loss = log_loss(mini_dev_labels[:sample_limit], preds, labels = mini_dev_labels[:sample_limit].unique())\n",
    "print('The multiclass loss of ANN model is %.4f' % total_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
